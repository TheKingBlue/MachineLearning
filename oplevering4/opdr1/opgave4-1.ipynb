{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Woordvectoren\n",
    "\n",
    "Deze opdracht staat in het teken van *word vectors*. Zoals tijdens het theoretische deel is toegelicht, representeren we in *Natural Language Processing* (*NLP*) elk woord als een pan-dimensionale vector van getallen. Deze vector is gerelateerd aan de betekenis van het woord. Voor deze module voert het te ver om dergelijke [*embeddings*](https://en.wikipedia.org/wiki/Word_embedding) zelf uit te programmeren, dus maken we gebruik van al getrainde modellen. In het echte leven is het ook zeer ongebruikelijk om embeddings zelf te programmeren, omdat het veel tijd en energie kost en ze eenvoudig beschikbaar zijn.\n",
    "\n",
    "In deze opgave gebruiken we *word embeddings* om de hoofdstad van een land te bepalen. We maken hierbij gebruik van de cosinusgelijkheid en de euclidische afstand, die beiden in het hoorcollege zijn toegelicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importeren van de data en de libraries\n",
    "\n",
    "Zoals gebruikelijk beginnen we met het imporeren van de noodzakelijke python-libraries en het laden van de dataset. Voor het gemak maken we weer gebruik van [een Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html) om dat data in op te slaan – een techniek die heel veel wordt gebruikt in machine-learning-projecten. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run deze cel om de packages te laden.\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import get_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city1</th>\n",
       "      <th>country1</th>\n",
       "      <th>city2</th>\n",
       "      <th>country2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bern</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city1 country1    city2     country2\n",
       "0  Athens   Greece  Bangkok     Thailand\n",
       "1  Athens   Greece  Beijing        China\n",
       "2  Athens   Greece   Berlin      Germany\n",
       "3  Athens   Greece     Bern  Switzerland\n",
       "4  Athens   Greece    Cairo        Egypt"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run deze cel om de data te laden.\n",
    "data = pd.read_csv('data/capitals.txt', delimiter=' ')\n",
    "data.columns = ['city1', 'country1', 'city2', 'country2']\n",
    "\n",
    "# een beeld van de data\n",
    "data.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de cel hieronder laden we de *word-embedding* die, zoals gezegd, vanuit een getraind model komt. Voor de volledigheid: deze embedding is een subset van [een project van Google](https://code.google.com/archive/p/word2vec/). In deze embedding zitten maar 243 woorden, maar voor deze opgave is dat prima. De woorden zijn opgeslagen als een python dictionary, waarvan de *key* het woord is en de *value* een driehonderd-dimensionale vector die de betekenis representeert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = pickle.load(open(\"data/word_embeddings_subset.p\", \"rb\"))\n",
    "len(word_embeddings)  # 243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grootte van de vector voor Berlijn: 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"grootte van de vector voor Berlijn: {word_embeddings['Berlin'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 1: Voorspellen van de relaties tussen woorden.\n",
    "\n",
    "We gaan een functie maken die de gegeven *word embeddings* gebruikt om de relatie tussen woorden te voorspellen. Deze functie krijgt drie parameters: de eerste twee zijn op een bepaalde manier aan elkaar gerelateerd en de functie geeft een nieuw woord terug dat eenzelfde relatie heeft met het gegeven derde woord. Wanneer we bijvoorbeeld de functie aanroepen met `Athene`, `Griekenland` en `Bankok`, moet de functie `Thailand` teruggeven (Athene staat immers tot Griekenland als Bankok staat tot Thailand).\n",
    "\n",
    "![uitleg van rekenen met woordvectoren](imgs/vectors.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cosinusgelijkheid\n",
    "\n",
    "Om de functie te kunnen maken, moeten we de cosinusgelijkheid van twee vectoren kunnen bepalen. Deze is hieronder gegeven:\n",
    "\n",
    "$$\\cos (\\theta)=\\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\|\\|\\mathbf{B}\\|}=\\frac{\\sum_{i=1}^{n} A_{i} B_{i}}{\\sqrt{\\sum_{i=1}^{n} A_{i}^{2}} \\sqrt{\\sum_{i=1}^{n} B_{i}^{2}}}\\tag{1}$$\n",
    "\n",
    "waarbij\n",
    "$A$ en $B$ (woord)vectoren en $A_i$, $B_i$ het i-de element van die vector zijn. \n",
    "\n",
    "* Wanneer $A$ en $B$ gelijk zijn, levert dat $cos(\\theta) = 1$ op.\n",
    "* Wanneer $A$ en $B$ exact tegengesteld zijn ($A = -B$), levert dat $cos(\\theta) = -1$ op.\n",
    "* Als $cos(\\theta) =0$, dan zijn $A$ en $B$ *orthogonaal* ($cos(90\\degree) = 0$, weten we nog?).\n",
    "* Bij waarden tussen 0 en 1 hebben $A$ en $B$ een *hoge gelijkenis* (hoger is meer gelijk aan elkaar).\n",
    "* Bij waarden tussen 0 en -1 hebben $A$ en $B$ een *lage gelijkenis* (lager is minder gelijk aan elkaar).\n",
    "\n",
    "Maak de functie `cosine_similarity` in de cel hieronder. Maak hierbij gebruik van `numpy.dot` en `numpy.linalg.norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    '''\n",
    "    Input:\n",
    "        A: een woordvector als numpy array\n",
    "        B: een woordvector als numpy array\n",
    "    Output:\n",
    "        cos: numerieke waarde van de cosinusgelijkheid tussen A en B\n",
    "    '''\n",
    "    # YOUR CODE HERE (vervang None door de juiste waarden)\n",
    "    dot = np.dot(A, B)\n",
    "    norma = np.linalg.norm(A)\n",
    "    normb = np.linalg.norm(B)\n",
    "    cos = dot / (norma * normb)\n",
    "    \n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(king, queen): 0.6510956287384033\n",
      "dit zou ongeveer 0.651 moeten zijn\n"
     ]
    }
   ],
   "source": [
    "king = word_embeddings['king']\n",
    "queen = word_embeddings['queen']\n",
    "\n",
    "print (f'cosine_similarity(king, queen): {cosine_similarity(king, queen)}')\n",
    "print ('dit zou ongeveer 0.651 moeten zijn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Euclidische afstand\n",
    "\n",
    "Maak nu een functie `euclidian` die de euclidische afstand tussen twee vectoren bepaalt. Maak hierbij weer gebruik van `numpy.linalg.norm`. De Euclidische afstand tussen twee vectoren is als volgt:\n",
    "\n",
    "$$ \\begin{aligned} d(\\mathbf{A}, \\mathbf{B})=d(\\mathbf{B}, \\mathbf{A}) &=\\sqrt{\\left(A_{1}-B_{1}\\right)^{2}+\\left(A_{2}-B_{2}\\right)^{2}+\\cdots+\\left(A_{n}-B_{n}\\right)^{2}} \\\\ &=\\sqrt{\\sum_{i=1}^{n}\\left(A_{i}-B_{i}\\right)^{2}} \\end{aligned}$$\n",
    "\n",
    "* $A$ en $B$ zijn (opnieuw) twee (woord)vectoren.\n",
    "* $n$ is het aantal elementen in de vector.\n",
    "* Hoe meer de twee woorden op elkaar lijken, hoe meer deze afstand gelijk is aan nul (0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(A, B):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A: een woordvector als numpy array\n",
    "        B: een woordvector als numpy array\n",
    "    Output:\n",
    "        d: numerieke waarde van de euclidische afstand tussen A en B\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE (vervang None door de juiste waarden)\n",
    "\n",
    "    d = np.linalg.norm(A-B)\n",
    "    \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean(king, queen): 2.4796924591064453\n",
      "zou ongeveer 2.48 moeten zijn\n"
     ]
    }
   ],
   "source": [
    "print (f'euclidean(king, queen): {euclidean(king, queen)}')\n",
    "print ('zou ongeveer 2.48 moeten zijn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stap 1.3: zoeken van het land op basis van de hoofdstad\n",
    "\n",
    "Nu maken we de functie `get_countries` waarmee we de hoofdstad van een land kunnen bepalen op basis van de twee gegeven woorden, zoals in het begin van deze notebook is beschreven. \n",
    "\n",
    "```python\n",
    "get_country('Athens', 'Greece', 'Baghdad')\n",
    "# Retourneert 'Iraq'\n",
    "```\n",
    "\n",
    "1. Denk terug aan het voorbeeld hierboven: `King - Man + Woman = Queen`. Implementeer dit idee in de cel hieronder, waarbij je de functies gebruikt die we in de vorige twee stappen hebben gezet.\n",
    "\n",
    "2. Bepaal de cosinussimulariteit tussen de gegeven woorden en elk woord in de dictionary.\n",
    "\n",
    "3. Retourneer een dictionary van vijf woorden uit de embedding met de hoogste similariteit, gesorteerd op similariteitsscore, samen met hun similariteitsscore.\n",
    "\n",
    "__LET OP__ dat je niet een woord teruggeeft dat al gegeven was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_countries(city1, country1, city2, embeddings):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        city1: string met de hoofdstad van een land\n",
    "        country1: string met dat land \n",
    "        city2: string met een hoofdstad\n",
    "        embeddings: dictionary met als keys de woorden en als values hun embeddings\n",
    "    Output:\n",
    "        countries: dictionary met de vijf meest gelijkende landen en hun similariteitsscore\n",
    "    \"\"\"\n",
    "    countries = {}\n",
    "\n",
    "    vec =  embeddings[country1] - embeddings[city1] + embeddings[city2]\n",
    "    \n",
    "    for key, value in embeddings.items():\n",
    "        if key not in [city1, country1, city2]:\n",
    "            countries[key] = cosine_similarity(vec, value)\n",
    "\n",
    "    countries = dict(sorted(countries.items(), key=lambda x:x[1], reverse=True)[:5])\n",
    "\n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woord met de hoogste waarde: Egypt (0.7626820802688599\n",
      "(Egypt met als waarde ongeveer 0.763\n"
     ]
    }
   ],
   "source": [
    "vals = get_countries('Athens', 'Greece', 'Cairo', word_embeddings)\n",
    "if len(vals) > 0:\n",
    "    hoogste_woord = list(vals.keys())[0]\n",
    "    hoogste_waarde = list(vals.values())[0]\n",
    "    print (f'Woord met de hoogste waarde: {hoogste_woord} ({hoogste_waarde}')\n",
    "    print ('(Egypt met als waarde ongeveer 0.763')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stap 1.4 accuratesse\n",
    "\n",
    "Bepaal nu de accuratesse van het model op basis van de gegeven dataset:\n",
    "\n",
    "$$\n",
    "acc = \\frac{n_{corr}}{n_{tot}}\n",
    "$$\n",
    "\n",
    "waarbij $n_{corr}$ het aantal *correcte* voorspellingen is en $n_{tot}$ het *totaal* aantal voorspellingen is. Je moet over elke regel van de dataset lopen en het woord in de methode `get_country` stoppen.\n",
    "\n",
    "__Tip :__ Je kunt gebruik maken van [`pandas.DataFrame.iterrows`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(word_embeddings, data):\n",
    "    '''\n",
    "    Input:\n",
    "        word_embeddings: dictionary met als keys de woorden en als values hun embeddings\n",
    "        data: pandas dataframe met land-hoofdstad paren\n",
    "    \n",
    "    Output:\n",
    "        accuracy: accuratesse van het model\n",
    "    '''\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    ncorr = 0\n",
    "    ntot = len(data)\n",
    "    for _, row in data.iterrows():\n",
    "        vals = get_countries(row[\"city1\"], row[\"country1\"], row[\"city2\"], word_embeddings)\n",
    "        if(list(vals.keys())[0] == row[\"country2\"]):\n",
    "            ncorr += 1\n",
    "\n",
    "    accuracy = ncorr/ntot\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal nu de accuratesse van het model, door onderstaande cel te runnen. __Let op :__ dat kan wel enige tientallen seconden duren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratesse is 0.92\n",
      "zou zo ongeveer 0.92 moeten zijn\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(word_embeddings, data)\n",
    "print (f\"Accuratesse is {accuracy:.2f}\")\n",
    "print ('zou zo ongeveer 0.92 moeten zijn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 2: plotten van de vectoren met behulp van PCA\n",
    "\n",
    "We gaan nu de dimensionaliteit van de vectoren reduceren en de afstand tussen de vectoren bekijken. We maken hiervoor gebruik van [*Hoofdcomponentenanalyse*](https://nl.wikipedia.org/wiki/Hoofdcomponentenanalyse) ([*Principle Component Analysis*](https://en.wikipedia.org/wiki/Principal_component_analysis)). \n",
    "\n",
    "Zoals je hebt gezien werken we met een driehonderd-dimensionale vectorruimte. Hoewel de computers hier wel mee om kunnen gaan, is het lastig om hier een plaatje van de creëren. Om dit toch kunnen doen moeten we het aantal dimensies reduceren (de zogenaamde *dimensionaliteitsreductie*, of in het Engels: *dimensionality reduction*). Eén van de meest gebruikte technieken hiervoor is PCA (hoewel dat eigenlijk geen reductie- maar een *transformatie*techniek is).\n",
    "\n",
    "Zoals tijdens het hoorcollege is toegelicht, projecteert PCA de vectoren op een ander assenstelsel waarmee de maximale informatie uit de originele vectoren wordt behouden. In dit specifieke geval zijn we op zoek naar die vectoren waarvan de euclidische afstand tot de oorspronkelijke vectoren *minimaal* is.\n",
    "\n",
    "Vectoren die in de oorspronkelijke dataset vlak bij elkaar zitten, zullen dan ook in de gereduceerde dimensionaliteit dicht bij elkaar zitten. De vectoren voor bijvoorbeeld de woorden 'sad', 'happy', 'joyful' beschrijven allemaal bepaalde gevoelens en zullen vlak bij elkaar zitten. \n",
    "\n",
    "Omdat we de boel als een 2D-plaatje willen weergeven, moeten we alle woordvectoren eerst met behulp van PCA reduceren tot een twee-dimensionale vector reduceren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder staat een stappenplan:\n",
    "\n",
    "1. Normaliseer de data (maak gebruik van [`numpy.mean`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html).\n",
    "2. Bereken de covariantiematrix $\\Sigma$ (maak gebruik van [`numpy.cov`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html).\n",
    "3. Bereken de eigenvectors en eigenvalues van $\\Sigma$ (maak gebruik van [`numpy.linalg.eigh`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eigh.html).\n",
    "4. Sorteer deze eigenvectors en eigenvalues van hoog naar laag op eigenvalues (check [`numpy.argsort`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html).\n",
    "5. Maak een subset van deze gesorteerde eigenvectors (gebruik de parameter `n_components`)\n",
    "6. Vermenigvuldig deze subset van eigenvectors met de oorspronkelijke data\n",
    "7. Retourneer deze vermenigvuldiging; als het goed is, is de `shape` van deze geretourneerde matrix `(m, n_components)`.\n",
    "\n",
    "Het plaatje hieronder geeft het proces grafisch weer.\n",
    "\n",
    "![Het resultaat van deze oefening](imgs/word_embf.jpeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca(X, n_components=2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: een matrix van (m,n) waarbij elke regel een woordvector bevat\n",
    "        n_components: het aantal componenten dat teruggegeven moet worden\n",
    "    Output:\n",
    "        X_reduced: de data getransformeerd tot 2 dims/columns + geregenereerde originele data\n",
    "    \"\"\"\n",
    "\n",
    "    X_reduced = None\n",
    "\n",
    "    # normaliseer de data\n",
    "    standardized_data = (X - X.mean(axis = 0)) / X.std(axis = 0)\n",
    "\n",
    "    # coveriance matrix berekenen\n",
    "    covariance_matrix = np.cov(standardized_data, ddof = 1, rowvar = False)\n",
    "\n",
    "    # eigenvalues en eigenvectors berekenen\n",
    "    e_val, e_vec = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    # bereken sorteer orde voor het sorteren van eigenvalues en eigenvectors op basis van de eigenvalues\n",
    "    sort_order = np.argsort(e_val)[::-1] \n",
    "\n",
    "    # sorteer eigenvalues en eigenvectors met de sorteer orde\n",
    "    sorted_val = e_val[sort_order]\n",
    "    sorted_vec = e_vec[:,sort_order] \n",
    "    \n",
    "    # maak subset van de gesorteerde eigenvectors\n",
    "    subset = sorted_vec[:,:n_components]\n",
    "\n",
    "    # Vermenigvuldig subset met de oorspronkelijke data (genormaliseerd)\n",
    "    X_reduced = np.matmul(standardized_data, subset)\n",
    "    \n",
    "    return X_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignele matrix was (3, 10)\n",
      "Nieuwe matrix is (3, 2) \n",
      "Output van de functie `compute_pca`:\n",
      "[[-1.80913582+0.j -2.31550476+0.j]\n",
      " [-1.76788619+0.j  2.3333748 +0.j]\n",
      " [ 3.577022  +0.j -0.01787004+0.j]]\n"
     ]
    }
   ],
   "source": [
    "# Testing testing one, two, three\n",
    "np.random.seed(1)\n",
    "X = np.random.rand(3, 10)\n",
    "X_reduced = compute_pca(X, n_components=2)\n",
    "print(f\"Orignele matrix was {X.shape}\")\n",
    "print(f\"Nieuwe matrix is {X_reduced.shape} \")\n",
    "print (\"Output van de functie `compute_pca`:\")\n",
    "print(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de cel hieronder gebruiken we de functie `compute_pca` om een plot te maken van een aantal woorden. Je kunt deze cel eenvoudig runnen. Wat valt je op aan het resultaat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kyra\\Documents\\HBO_ICT\\JAAR_4\\KMO2 (ML)\\MachineLearning\\ml\\lib\\site-packages\\matplotlib\\collections.py:192: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  offsets = np.asanyarray(offsets, float)\n",
      "c:\\Users\\Kyra\\Documents\\HBO_ICT\\JAAR_4\\KMO2 (ML)\\MachineLearning\\ml\\lib\\site-packages\\matplotlib\\text.py:1475: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x = float(self.convert_xunits(x))\n",
      "c:\\Users\\Kyra\\Documents\\HBO_ICT\\JAAR_4\\KMO2 (ML)\\MachineLearning\\ml\\lib\\site-packages\\matplotlib\\text.py:1477: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  y = float(self.convert_yunits(y))\n",
      "c:\\Users\\Kyra\\Documents\\HBO_ICT\\JAAR_4\\KMO2 (ML)\\MachineLearning\\ml\\lib\\site-packages\\matplotlib\\text.py:757: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  posx = float(self.convert_xunits(self._x))\n",
      "c:\\Users\\Kyra\\Documents\\HBO_ICT\\JAAR_4\\KMO2 (ML)\\MachineLearning\\ml\\lib\\site-packages\\matplotlib\\text.py:758: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  posy = float(self.convert_yunits(self._y))\n",
      "c:\\Users\\Kyra\\Documents\\HBO_ICT\\JAAR_4\\KMO2 (ML)\\MachineLearning\\ml\\lib\\site-packages\\matplotlib\\text.py:897: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x = float(self.convert_xunits(self._x))\n",
      "c:\\Users\\Kyra\\Documents\\HBO_ICT\\JAAR_4\\KMO2 (ML)\\MachineLearning\\ml\\lib\\site-packages\\matplotlib\\text.py:898: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  y = float(self.convert_yunits(self._y))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = ['oil', 'gas', 'happy', 'sad', 'city', 'town',\n",
    "         'village', 'country', 'continent', 'petroleum', 'joyful']\n",
    "\n",
    "X = get_vectors(word_embeddings, words)\n",
    "result = compute_pca(X, 2)\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0] - 0.05, result[i, 1] + 0.1))\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "schema_names": [
    "NLPC1-3"
   ]
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
